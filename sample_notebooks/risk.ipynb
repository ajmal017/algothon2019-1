{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Scores, Risk, Alphas and Holdings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the principles below are similar to those applied by professional research teams. We are\n",
    "going to use open source tools only and therefore will need to keep the examples simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw signal to scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scores are build on a raw signal. Raw Signals – Any raw data used to predict future returns\n",
    "e.g. past stock returns, survey values, interest rates, earnings estimate, buy/sell recommendation.\n",
    "Features of raw signals: - They are not a direct forecast of exceptional return - They have a variety\n",
    "of units and scales\n",
    "Real signal data is noisy, contains the true value + error. We can’t observe the true value or\n",
    "attempt to forecast it from noisy data.\n",
    "Exponential Moving Average – EMA is used below to smooth and standardize the raw signal.\n",
    "We could apply two types of scoring (or even both). - Time Series Scoring. Current score of an\n",
    "asset is relative to its own history in the past. Is the option relatively cheaper or more expensive\n",
    "compared to historical values? - Cross Sectional Scoring. Current score of an asset is relative to\n",
    "its asset peers today. Is the option more or less expensive compared to other stocks in the same\n",
    "sector?\n",
    "Below we are reading the ‘raw signal’ from pack 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as m\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xscore(df):\n",
    "    \"\"\" Cross sectionally score/standardize two or three dimensional timeseries\"\"\"\n",
    "    return df.sub(df.mean(axis=1), axis=0).div(df.std(axis=1), axis=0)\n",
    "\n",
    "def tscore(df, halflife):\n",
    "    \"\"\"Standardizes the input\n",
    "    - Returns:\n",
    "    timeseries of scores, means and volatility\n",
    "    \"\"\"\n",
    "    dfmean = df.ewm(halflife=halflife).mean()\n",
    "    dfstd = df.ewm(halflife=halflife).std()\n",
    "    return (df - dfmean) / dfstd, dfmean, dfstd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read returns and raw signal\n",
      "Calculating scores and volatilities\n"
     ]
    }
   ],
   "source": [
    "data_root = r'D:\\Algothonslack\\Packs'\n",
    "print('Read returns and raw signal')\n",
    "# read previously calculated signal forecast\n",
    "forecasts = pd.read_csv(os.path.join(data_root,'forecast_example_data.csv')).set_index('period')\n",
    "# read the actual returns of the assets\n",
    "returns = pd.read_csv(os.path.join(data_root, 'returns_example_data.csv')).set_index('period')\n",
    "print('Calculating scores and volatilities')\n",
    "forecasts.index = forecasts.index.astype(pd.datetime)\n",
    "returns.index = returns.index.astype(pd.datetime)\n",
    "# halflife relates to the speed fo the signal and requires some additional \n",
    "tscores, tmean, tstd = tscore(forecasts, halflife=52)\n",
    "# for xscoring, vol scale the signals first\n",
    "volScaled = forecasts / tstd\n",
    "xscores = xscore(volScaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure no peak ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this by shifting the scores by at least one time period. That means that the scores we\n",
    "calculate with data from today can be used to predict returns only for the following date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag the signals to avoid peekahead\n",
    "tscores = tscores.shift(1)\n",
    "xscores = xscores.shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the risk data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating risk\n"
     ]
    }
   ],
   "source": [
    "print('Calculating risk')\n",
    "# Estimating the risk through a rolling 22 day sample and annualising.\n",
    "# The rolling window here can be set according to what makes sense for the # Since it take a bit to generate, you could calculate it once and then\n",
    "# read it from disk\n",
    "use_cached_risk = True\n",
    "risk_file = os.path.join(data_root,'risk.pickle')\n",
    "if os.path.exists(risk_file) and use_cached_risk:\n",
    "    with open(risk_file, 'rb') as handle:\n",
    "        riskMx = pickle.load(handle)\n",
    "else:\n",
    "    riskMx = returns.rolling(22).cov() * 252\n",
    "    with open(risk_file, 'wb') as handle:\n",
    "        pickle.dump(riskMx, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Alphas and Holdings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we convert scores to alphas using the Grinold-Khan formula. where the IC is the information\n",
    "coefficient and sigma is the signals risk. The IC can be derived or set as a constant and it represents\n",
    "a portfolio manager’s ‘skill’ in selecting securities. A default value of IC can be set to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\alpha = $ score $* \\mbox{ IC }* \\sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Grinold-Khan formula is only one way to generate the alphas, other methods exist including\n",
    "discretionary views alphas which come from specialist internal or external surveys.\n",
    "Then we calculate the holdings by maximing the utility function in the absence of any constraints.\n",
    "The lamda here is a constant representing risk aversion which we can set to 1. This is\n",
    "one of the simplest ways to run an optimization of asset alphas in relation to their risk and the\n",
    "investor’s risk aversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$U = \\alpha h - \\lambda V h^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\partial U}{\\partial h} = \\alpha - 2 \\lambda V h$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ h = \\frac{\\alpha V^{-1}}{2\\lambda}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_alpha_and_holdings(score, vols, ic=0.05):\n",
    "    \"\"\"Compute alphas from scores\n",
    "    Args:\n",
    "    score: Z scores\n",
    "    ic: Information coeffcient\n",
    "    vols: Asset volatilites\n",
    "    Returns:\n",
    "    Alphas (i.e. alpha = IC * score * volatility)\n",
    "    \"\"\"\n",
    "    alphas = pd.DataFrame()\n",
    "    holdings = pd.DataFrame()\n",
    "    vol_data = vols.values.reshape(int(len(vols.values) / len(vols.columns)),len(vols.columns),len(vols.columns))\n",
    "                                   \n",
    "    for ind in range(len(score.index)):\n",
    "        currRiskMx = np.array(vol_data[ind, :,:])\n",
    "        if not np.isnan(currRiskMx).all():\n",
    "            invmx = np.linalg.inv(currRiskMx)\n",
    "            alpha = tscores.iloc[ind, :] * ic * np.diag(currRiskMx) ** 0.5\n",
    "            alphas = alphas.append(alpha)\n",
    "            holding_data = alpha.dot(invmx) / 2\n",
    "            holding_series = pd.Series(holding_data, index=alpha.index)\n",
    "            holding_series.name = alpha.name\n",
    "            holdings = holdings.append(holding_series)\n",
    "    return alphas, holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating alphas and holdings\n",
    "alphas, holdings = gen_alpha_and_holdings(xscores, riskMx)\n",
    "alphas.to_csv(os.path.join(data_root,'alphas.csv'))\n",
    "holdings.to_csv(os.path.join(data_root, 'holdings.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting of Holdings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many metrics to be calculated once the model holdings have been generated. For this\n",
    "simple example we will start with Information Ratio (IR) and Turnover.\n",
    "IR is the risk-adjusted rate of return. IR can be used not only on individual assets or the\n",
    "model as a whole but also on holdings generated from differently lagged scores or with different\n",
    "combinations of assets which can test the robustness of the signal.\n",
    "Turnover represents the percentage of the portfolio holdings that have changed over a time\n",
    "period. A high turnover signal can be problematic when used on non highly liquid assets or when\n",
    "the tcost and/or market impact are high. This suggests that the signal’s trading frequency, assets,\n",
    "optimization or tcost model should be reviewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_str(df):\n",
    "    \"\"\" Returns the inferred frequency of the timeseries\n",
    "    \"\"\"\n",
    "    if df.index.inferred_freq is None:\n",
    "        return\n",
    "    inferred_freq = df.index.inferred_freq.split('-')[0]\n",
    "    if inferred_freq in ('B', 'D'): # daily\n",
    "        return 'daily'\n",
    "    elif inferred_freq == 'W': # weekly\n",
    "        return 'weekly'\n",
    "    elif inferred_freq in ('M', 'BM', 'MS', 'BMS'): # monthly\n",
    "        return 'monthly'\n",
    "    elif inferred_freq in ('Q', 'BQ', 'QS', 'BQS'): # quarterly\n",
    "        return 'quarterly'\n",
    "    elif inferred_freq in ('A', 'BA', 'AS', 'BAS'): # annual\n",
    "        return 'annual'\n",
    "    elif inferred_freq == 'H': # hourly\n",
    "        return 'hourly'\n",
    "    elif inferred_freq == 'T': # minutely\n",
    "        return 'minutely'\n",
    "    elif inferred_freq == 'S': # secondly\n",
    "        return 'secondly'\n",
    "    elif inferred_freq == 'L': # millisecondly\n",
    "        return 'millisecondly'\n",
    "    elif inferred_freq == 'U': # microsecondly\n",
    "        return 'microsecondly'\n",
    "    else:\n",
    "        annual_freq = round(freq(df))\n",
    "        if annual_freq == 1:\n",
    "            return 'annual'\n",
    "        elif annual_freq == 4:\n",
    "            return 'quarterly'\n",
    "        elif annual_freq == 12:\n",
    "            return 'monthly'\n",
    "        elif annual_freq == 52:\n",
    "            return 'weekly'\n",
    "        elif 250 <= annual_freq <= 365:\n",
    "            return 'daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_lookup = {'annual': 1, 'quarterly': 4, 'monthly': 12, 'weekly': 52, 'hourly': 260 * 24, 'minutely': 260 * 24 * 60,  'microsecondly': 260 * 24 * 60 * 1e6}\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(df, inferred=False):\n",
    "    \"\"\"Compute frequency of timeseries in units of periods per year\n",
    "    Args:\n",
    "    df: timeseries\n",
    "    inferred (bool): Infer the frequency (default is True). If True return annual: 1\n",
    "    quarterly: 4\n",
    "    monthly: 12\n",
    "    weekly: 52\n",
    "    daily: 260\n",
    "    \"\"\"\n",
    "    #empirical_freq = (df.shape[0] - 1) / (df.index[-1].days - df.index[0].days)\n",
    "    if inferred:\n",
    "        s = freq_str(df)\n",
    "        if s in freq_lookup:\n",
    "            return freq_lookup[s]\n",
    "        else:\n",
    "            log.warning('Can not infer frequency')\n",
    "    else:\n",
    "        # default to daily frequency\n",
    "        return 260 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ir(df):\n",
    "    \"\"\"Compute realized information ratio\n",
    "    \"\"\"\n",
    "    mean = df.mean()\n",
    "    stdev = df.std()\n",
    "    annualization_factor = np.sqrt(freq(df))\n",
    "    if isinstance(stdev, pd.Series):\n",
    "        stdev.replace(0, np.nan, inplace=True)\n",
    "    elif stdev == 0:\n",
    "        stdev = np.nan\n",
    "    return mean / stdev * annualization_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnover(h, ret=None):\n",
    "    \"\"\"Compute average portfolio turnover\n",
    "    Args:\n",
    "    h: Holdings\n",
    "    ret: Optional asset returns used to adjust initial holdings\n",
    "    Returns:\n",
    "    Annualized absolute portfolio turnover\n",
    "    \"\"\"\n",
    "    h = h.fillna(0.0)\n",
    "    if ret is None:\n",
    "        h_initial = h.shift()\n",
    "    else:\n",
    "        h_initial = h.mul(1 + ret).div(1 + h.mul(ret).sum(axis=1), axis=0)\n",
    "    trades = h - h_initial\n",
    "    return trades.abs().sum(axis=1).mean() * freq(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate IR\n",
      "X0000   -0.807784\n",
      "X0001    0.176091\n",
      "X0002   -1.444355\n",
      "X0003   -0.517490\n",
      "X0004   -0.130676\n",
      "X0005    0.639562\n",
      "X0006    1.763498\n",
      "X0007    0.943258\n",
      "X0008   -0.448178\n",
      "X0009    0.084749\n",
      "X0010    0.152479\n",
      "X0011    1.015571\n",
      "X0012    1.305033\n",
      "X0013    0.483378\n",
      "X0014    1.500183\n",
      "X0015   -0.316819\n",
      "X0016    0.272968\n",
      "X0017    1.385198\n",
      "X0018   -0.097904\n",
      "X0019    0.315289\n",
      "X0020    1.675392\n",
      "X0021   -1.257452\n",
      "X0022    1.351893\n",
      "X0023   -0.963739\n",
      "X0024    1.836852\n",
      "X0025   -1.775731\n",
      "X0026    0.829655\n",
      "X0027    0.722068\n",
      "X0028    1.112634\n",
      "X0029    1.355711\n",
      "           ...   \n",
      "X0070    1.524877\n",
      "X0071    1.548724\n",
      "X0072   -0.829707\n",
      "X0073    0.934761\n",
      "X0074   -0.197428\n",
      "X0075   -0.221506\n",
      "X0076    1.019060\n",
      "X0077   -0.112239\n",
      "X0078    0.414770\n",
      "X0079   -0.606003\n",
      "X0080   -1.926062\n",
      "X0081   -0.222489\n",
      "X0082   -0.732526\n",
      "X0083   -1.524440\n",
      "X0084    1.537653\n",
      "X0085    1.404291\n",
      "X0086    0.320020\n",
      "X0087   -0.575189\n",
      "X0088    0.365376\n",
      "X0089   -1.315264\n",
      "X0090   -1.361866\n",
      "X0091   -0.692478\n",
      "X0092   -1.319289\n",
      "X0093   -1.631213\n",
      "X0094    0.719096\n",
      "X0095    0.199578\n",
      "X0096   -0.644715\n",
      "X0097    0.942412\n",
      "X0098    1.404715\n",
      "X0099    0.070758\n",
      "Length: 100, dtype: float64\n",
      " ##### \n",
      "calculate Turnover\n",
      "7.809504485350728e+19\n"
     ]
    }
   ],
   "source": [
    "print('calculate IR')\n",
    "print(ir(holdings))\n",
    "print(' ##### ')\n",
    "print('calculate Turnover')\n",
    "print(turnover(holdings,returns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
